Same as 10 500 Epochs

(sump-venv) (sump-venv) [rda2tc@affogato13 12encoderDreamBigger]$ python trainModel.py 
(23201,)
(20880,)
2022-04-18 10:43:35.249967: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-18 10:43:41.239049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1
2022-04-18 10:43:41.288767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10417 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1
2022-04-18 10:43:41.290776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10417 MB memory:  -> device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1
2022-04-18 10:43:41.292264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10417 MB memory:  -> device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 64, 1024, 32)      320       
                                                                 
 batch_normalization (BatchN  (None, 64, 1024, 32)     128       
 ormalization)                                                   
                                                                 
 leaky_re_lu (LeakyReLU)     (None, 64, 1024, 32)      0         
                                                                 
 max_pooling2d (MaxPooling2D  (None, 32, 512, 32)      0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 32, 512, 64)       18496     
                                                                 
 batch_normalization_1 (Batc  (None, 32, 512, 64)      256       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_1 (LeakyReLU)   (None, 32, 512, 64)       0         
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 16, 256, 64)      0         
 2D)                                                             
                                                                 
 conv2d_2 (Conv2D)           (None, 16, 256, 64)       36928     
                                                                 
 batch_normalization_2 (Batc  (None, 16, 256, 64)      256       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_2 (LeakyReLU)   (None, 16, 256, 64)       0         
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 8, 128, 64)       0         
 2D)                                                             
                                                                 
 conv2d_3 (Conv2D)           (None, 8, 128, 64)        36928     
                                                                 
 batch_normalization_3 (Batc  (None, 8, 128, 64)       256       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_3 (LeakyReLU)   (None, 8, 128, 64)        0         
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 4, 64, 64)        0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 16384)             0         
                                                                 
 dense (Dense)               (None, 16384)             268451840 
                                                                 
 dense_1 (Dense)             (None, 16384)             268451840 
                                                                 
 reshape (Reshape)           (None, 4, 64, 64)         0         
                                                                 
 conv2d_4 (Conv2D)           (None, 4, 64, 64)         36928     
                                                                 
 batch_normalization_4 (Batc  (None, 4, 64, 64)        256       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_4 (LeakyReLU)   (None, 4, 64, 64)         0         
                                                                 
 up_sampling2d (UpSampling2D  (None, 8, 128, 64)       0         
 )                                                               
                                                                 
 conv2d_5 (Conv2D)           (None, 8, 128, 64)        36928     
                                                                 
 batch_normalization_5 (Batc  (None, 8, 128, 64)       256       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_5 (LeakyReLU)   (None, 8, 128, 64)        0         
                                                                 
 up_sampling2d_1 (UpSampling  (None, 16, 256, 64)      0         
 2D)                                                             
                                                                 
 conv2d_6 (Conv2D)           (None, 16, 256, 64)       36928     
                                                                 
 batch_normalization_6 (Batc  (None, 16, 256, 64)      256       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_6 (LeakyReLU)   (None, 16, 256, 64)       0         
                                                                 
 up_sampling2d_2 (UpSampling  (None, 32, 512, 64)      0         
 2D)                                                             
                                                                 
 conv2d_7 (Conv2D)           (None, 32, 512, 32)       18464     
                                                                 
 batch_normalization_7 (Batc  (None, 32, 512, 32)      128       
 hNormalization)                                                 
                                                                 
 leaky_re_lu_7 (LeakyReLU)   (None, 32, 512, 32)       0         
                                                                 
 up_sampling2d_3 (UpSampling  (None, 64, 1024, 32)     0         
 2D)                                                             
                                                                 
 conv2d_8 (Conv2D)           (None, 64, 1024, 1)       289       
                                                                 
=================================================================
Total params: 537,127,681
Trainable params: 537,126,785
Non-trainable params: 896
_________________________________________________________________
None
Epoch 1/500
2022-04-18 10:43:45.574026: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
2022-04-18 10:43:46.817338: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-04-18 10:43:46.910268: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-04-18 10:43:47.342135: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
652/652 [==============================] - 223s 336ms/step - loss: 0.5853 - val_loss: 0.5823
Epoch 2/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5821 - val_loss: 0.5822
Epoch 3/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5820 - val_loss: 0.5821
Epoch 4/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5820 - val_loss: 0.5821
Epoch 5/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5819 - val_loss: 0.5821
Epoch 6/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5819 - val_loss: 0.5821
Epoch 7/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 8/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5819 - val_loss: 0.5821
Epoch 9/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 10/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 11/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 12/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 13/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 14/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 15/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 16/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 17/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 18/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5819 - val_loss: 0.5820
Epoch 19/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5819 - val_loss: 0.5819
Epoch 20/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 21/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 22/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 23/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 24/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 25/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 26/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 27/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 28/500
652/652 [==============================] - 139s 212ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 29/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 30/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 31/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 32/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 33/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 34/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 35/500
652/652 [==============================] - 160s 246ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 36/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 37/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 38/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 39/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 40/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 41/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 42/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 43/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 44/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 45/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 46/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 47/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 48/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 49/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 50/500
652/652 [==============================] - 137s 211ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 51/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5818 - val_loss: 0.5820
Epoch 52/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 53/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 54/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5818 - val_loss: 0.5819
Epoch 55/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5817 - val_loss: 0.5818
Epoch 56/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5816 - val_loss: 0.5816
Epoch 57/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 58/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5815 - val_loss: 0.5818
Epoch 59/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 60/500
652/652 [==============================] - 159s 244ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 61/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 62/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 63/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5815 - val_loss: 0.5822
Epoch 64/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 65/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5815 - val_loss: 0.5819
Epoch 66/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5815 - val_loss: 0.5819
Epoch 67/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 68/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 69/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 70/500
652/652 [==============================] - 137s 211ms/step - loss: 0.5815 - val_loss: 0.5820
Epoch 71/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5815 - val_loss: 0.5819
Epoch 72/500
652/652 [==============================] - 138s 212ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 73/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 74/500
652/652 [==============================] - 137s 211ms/step - loss: 0.5815 - val_loss: 0.5821
Epoch 75/500
652/652 [==============================] - 148s 227ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 76/500
652/652 [==============================] - 160s 246ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 77/500
652/652 [==============================] - 159s 244ms/step - loss: 0.5815 - val_loss: 0.5820
Epoch 78/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5825
Epoch 79/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 80/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5819
Epoch 81/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 82/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 83/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5815 - val_loss: 0.5831
Epoch 84/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 85/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 86/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5815 - val_loss: 0.5815
Epoch 87/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5815 - val_loss: 0.5874
Epoch 88/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 89/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5815 - val_loss: 0.5819
Epoch 90/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5817
Epoch 91/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5815 - val_loss: 0.5818
Epoch 92/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 93/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5819
Epoch 94/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5814 - val_loss: 0.5822
Epoch 95/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 96/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5818
Epoch 97/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5814 - val_loss: 0.5818
Epoch 98/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 99/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5818
Epoch 100/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5814 - val_loss: 0.5827
Epoch 101/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 102/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 103/500
652/652 [==============================] - 137s 211ms/step - loss: 0.5814 - val_loss: 0.5815
Epoch 104/500
652/652 [==============================] - 137s 211ms/step - loss: 0.5815 - val_loss: 0.5819
Epoch 105/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5814 - val_loss: 0.5820
Epoch 106/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5814 - val_loss: 0.5817
Epoch 107/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5814 - val_loss: 0.5818
Epoch 108/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5814 - val_loss: 0.5820
Epoch 109/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5814 - val_loss: 0.5833
Epoch 110/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5814 - val_loss: 0.5816
Epoch 111/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5814 - val_loss: 0.5816
Epoch 112/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5814 - val_loss: 0.5815
Epoch 113/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5814 - val_loss: 0.5816
Epoch 114/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5815 - val_loss: 0.5816
Epoch 115/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5814 - val_loss: 0.5818
Epoch 116/500
652/652 [==============================] - 138s 212ms/step - loss: 0.5814 - val_loss: 0.5817
Epoch 117/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5814 - val_loss: 0.5822
Epoch 118/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5814 - val_loss: 0.5837
Epoch 119/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5814 - val_loss: 0.5821
Epoch 120/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5813 - val_loss: 0.5815
Epoch 121/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5809 - val_loss: 0.5810
Epoch 122/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5806 - val_loss: 0.5811
Epoch 123/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5805 - val_loss: 0.5807
Epoch 124/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5804 - val_loss: 0.5812
Epoch 125/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5803 - val_loss: 0.5807
Epoch 126/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5802 - val_loss: 0.5805
Epoch 127/500
652/652 [==============================] - 139s 213ms/step - loss: 0.5800 - val_loss: 0.5799
Epoch 128/500
652/652 [==============================] - 148s 226ms/step - loss: 0.5795 - val_loss: 0.5796
Epoch 129/500
652/652 [==============================] - 158s 242ms/step - loss: 0.5792 - val_loss: 0.5795
Epoch 130/500
652/652 [==============================] - 139s 213ms/step - loss: 0.5790 - val_loss: 0.5793
Epoch 131/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5789 - val_loss: 0.5790
Epoch 132/500
652/652 [==============================] - 159s 244ms/step - loss: 0.5787 - val_loss: 0.5789
Epoch 133/500
652/652 [==============================] - 146s 223ms/step - loss: 0.5779 - val_loss: 0.5780
Epoch 134/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5768 - val_loss: 0.5766
Epoch 135/500
652/652 [==============================] - 138s 212ms/step - loss: 0.5754 - val_loss: 0.5753
Epoch 136/500
652/652 [==============================] - 143s 220ms/step - loss: 0.5741 - val_loss: 0.5738
Epoch 137/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5730 - val_loss: 0.5729
Epoch 138/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5722 - val_loss: 0.5722
Epoch 139/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5715 - val_loss: 0.5715
Epoch 140/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5710 - val_loss: 0.5711
Epoch 141/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5706 - val_loss: 0.5706
Epoch 142/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5702 - val_loss: 0.5705
Epoch 143/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5699 - val_loss: 0.5701
Epoch 144/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5696 - val_loss: 0.5699
Epoch 145/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5693 - val_loss: 0.5697
Epoch 146/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5691 - val_loss: 0.5695
Epoch 147/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5689 - val_loss: 0.5694
Epoch 148/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5687 - val_loss: 0.5692
Epoch 149/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5685 - val_loss: 0.5691
Epoch 150/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5683 - val_loss: 0.5689
Epoch 151/500
652/652 [==============================] - 135s 208ms/step - loss: 0.5682 - val_loss: 0.5688
Epoch 152/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5681 - val_loss: 0.5687
Epoch 153/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5679 - val_loss: 0.5686
Epoch 154/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5678 - val_loss: 0.5686
Epoch 155/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5677 - val_loss: 0.5684
Epoch 156/500
652/652 [==============================] - 135s 208ms/step - loss: 0.5676 - val_loss: 0.5684
Epoch 157/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5675 - val_loss: 0.5683
Epoch 158/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5674 - val_loss: 0.5682
Epoch 159/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5673 - val_loss: 0.5682
Epoch 160/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5672 - val_loss: 0.5682
Epoch 161/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5671 - val_loss: 0.5681
Epoch 162/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5670 - val_loss: 0.5681
Epoch 163/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5669 - val_loss: 0.5681
Epoch 164/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5669 - val_loss: 0.5680
Epoch 165/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5668 - val_loss: 0.5679
Epoch 166/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5667 - val_loss: 0.5680
Epoch 167/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5667 - val_loss: 0.5680
Epoch 168/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5666 - val_loss: 0.5679
Epoch 169/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5666 - val_loss: 0.5678
Epoch 170/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5665 - val_loss: 0.5678
Epoch 171/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5665 - val_loss: 0.5678
Epoch 172/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5664 - val_loss: 0.5678
Epoch 173/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5663 - val_loss: 0.5678
Epoch 174/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5663 - val_loss: 0.5677
Epoch 175/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5663 - val_loss: 0.5678
Epoch 176/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5662 - val_loss: 0.5678
Epoch 177/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5662 - val_loss: 0.5677
Epoch 178/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5661 - val_loss: 0.5678
Epoch 179/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5661 - val_loss: 0.5677
Epoch 180/500
652/652 [==============================] - 135s 208ms/step - loss: 0.5660 - val_loss: 0.5677
Epoch 181/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5660 - val_loss: 0.5677
Epoch 182/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5660 - val_loss: 0.5677
Epoch 183/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5659 - val_loss: 0.5677
Epoch 184/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5659 - val_loss: 0.5678
Epoch 185/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5659 - val_loss: 0.5677
Epoch 186/500
652/652 [==============================] - 135s 208ms/step - loss: 0.5658 - val_loss: 0.5677
Epoch 187/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5658 - val_loss: 0.5677
Epoch 188/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5658 - val_loss: 0.5677
Epoch 189/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5657 - val_loss: 0.5677
Epoch 190/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5657 - val_loss: 0.5678
Epoch 191/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5657 - val_loss: 0.5677
Epoch 192/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5657 - val_loss: 0.5677
Epoch 193/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5656 - val_loss: 0.5677
Epoch 194/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5656 - val_loss: 0.5677
Epoch 195/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5656 - val_loss: 0.5677
Epoch 196/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5656 - val_loss: 0.5677
Epoch 197/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5655 - val_loss: 0.5677
Epoch 198/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5655 - val_loss: 0.5677
Epoch 199/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5655 - val_loss: 0.5676
Epoch 200/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5655 - val_loss: 0.5677
Epoch 201/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5655 - val_loss: 0.5678
Epoch 202/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5654 - val_loss: 0.5677
Epoch 203/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5654 - val_loss: 0.5677
Epoch 204/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5654 - val_loss: 0.5677
Epoch 205/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5654 - val_loss: 0.5677
Epoch 206/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5653 - val_loss: 0.5678
Epoch 207/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5653 - val_loss: 0.5677
Epoch 208/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5653 - val_loss: 0.5677
Epoch 209/500
652/652 [==============================] - 134s 204ms/step - loss: 0.5653 - val_loss: 0.5677
Epoch 210/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5653 - val_loss: 0.5678
Epoch 211/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5652 - val_loss: 0.5677
Epoch 212/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5652 - val_loss: 0.5678
Epoch 213/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5652 - val_loss: 0.5678
Epoch 214/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5652 - val_loss: 0.5678
Epoch 215/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5652 - val_loss: 0.5678
Epoch 216/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5652 - val_loss: 0.5678
Epoch 217/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5651 - val_loss: 0.5678
Epoch 218/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5651 - val_loss: 0.5678
Epoch 219/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5651 - val_loss: 0.5678
Epoch 220/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5651 - val_loss: 0.5678
Epoch 221/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5651 - val_loss: 0.5679
Epoch 222/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5651 - val_loss: 0.5678
Epoch 223/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5651 - val_loss: 0.5679
Epoch 224/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5650 - val_loss: 0.5678
Epoch 225/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5650 - val_loss: 0.5678
Epoch 226/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5650 - val_loss: 0.5679
Epoch 227/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5650 - val_loss: 0.5679
Epoch 228/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5650 - val_loss: 0.5678
Epoch 229/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5650 - val_loss: 0.5679
Epoch 230/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5650 - val_loss: 0.5679
Epoch 231/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 232/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 233/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 234/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 235/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 236/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 237/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 238/500
652/652 [==============================] - 189s 290ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 239/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5649 - val_loss: 0.5679
Epoch 240/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5648 - val_loss: 0.5679
Epoch 241/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5648 - val_loss: 0.5680
Epoch 242/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5648 - val_loss: 0.5679
Epoch 243/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5648 - val_loss: 0.5679
Epoch 244/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5648 - val_loss: 0.5679
Epoch 245/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5648 - val_loss: 0.5680
Epoch 246/500
652/652 [==============================] - 159s 244ms/step - loss: 0.5648 - val_loss: 0.5680
Epoch 247/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5648 - val_loss: 0.5679
Epoch 248/500
652/652 [==============================] - 183s 281ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 249/500
652/652 [==============================] - 175s 267ms/step - loss: 0.5647 - val_loss: 0.5679
Epoch 250/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 251/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5647 - val_loss: 0.5681
Epoch 252/500
652/652 [==============================] - 189s 290ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 253/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 254/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 255/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 256/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 257/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 258/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5647 - val_loss: 0.5680
Epoch 259/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 260/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 261/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 262/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 263/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 264/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 265/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 266/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 267/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 268/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 269/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 270/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5646 - val_loss: 0.5681
Epoch 271/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 272/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5645 - val_loss: 0.5681
Epoch 273/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5645 - val_loss: 0.5681
Epoch 274/500
652/652 [==============================] - 139s 213ms/step - loss: 0.5645 - val_loss: 0.5681
Epoch 275/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 276/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 277/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 278/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 279/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 280/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 281/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 282/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 283/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 284/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5645 - val_loss: 0.5682
Epoch 285/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5644 - val_loss: 0.5682
Epoch 286/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 287/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5644 - val_loss: 0.5682
Epoch 288/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5644 - val_loss: 0.5682
Epoch 289/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5644 - val_loss: 0.5682
Epoch 290/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 291/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 292/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 293/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5644 - val_loss: 0.5682
Epoch 294/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 295/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 296/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 297/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 298/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5644 - val_loss: 0.5683
Epoch 299/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 300/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5643 - val_loss: 0.5683
Epoch 301/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5643 - val_loss: 0.5683
Epoch 302/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 303/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 304/500
652/652 [==============================] - 166s 254ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 305/500
652/652 [==============================] - 223s 342ms/step - loss: 0.5643 - val_loss: 0.5683
Epoch 306/500
652/652 [==============================] - 154s 236ms/step - loss: 0.5643 - val_loss: 0.5683
Epoch 307/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 308/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5643 - val_loss: 0.5683
Epoch 309/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5643 - val_loss: 0.5683
Epoch 310/500
652/652 [==============================] - 135s 208ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 311/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 312/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 313/500
652/652 [==============================] - 162s 248ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 314/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 315/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 316/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 317/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5643 - val_loss: 0.5684
Epoch 318/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5642 - val_loss: 0.5684
Epoch 319/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5642 - val_loss: 0.5684
Epoch 320/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5642 - val_loss: 0.5684
Epoch 321/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 322/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5642 - val_loss: 0.5684
Epoch 323/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5642 - val_loss: 0.5684
Epoch 324/500
652/652 [==============================] - 140s 214ms/step - loss: 0.5642 - val_loss: 0.5684
Epoch 325/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 326/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 327/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5642 - val_loss: 0.5684
Epoch 328/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 329/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 330/500
652/652 [==============================] - 140s 214ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 331/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 332/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 333/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 334/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 335/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 336/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 337/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 338/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5642 - val_loss: 0.5685
Epoch 339/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5642 - val_loss: 0.5686
Epoch 340/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 341/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 342/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 343/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 344/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 345/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5685
Epoch 346/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5685
Epoch 347/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 348/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 349/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 350/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 351/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5687
Epoch 352/500
652/652 [==============================] - 139s 213ms/step - loss: 0.5641 - val_loss: 0.5687
Epoch 353/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5641 - val_loss: 0.5687
Epoch 354/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5641 - val_loss: 0.5687
Epoch 355/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 356/500
652/652 [==============================] - 142s 217ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 357/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5641 - val_loss: 0.5687
Epoch 358/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 359/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5687
Epoch 360/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5641 - val_loss: 0.5687
Epoch 361/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5641 - val_loss: 0.5686
Epoch 362/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 363/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 364/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 365/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 366/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 367/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 368/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 369/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 370/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 371/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 372/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 373/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 374/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 375/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 376/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 377/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 378/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 379/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 380/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 381/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 382/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 383/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 384/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5640 - val_loss: 0.5687
Epoch 385/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 386/500
652/652 [==============================] - 140s 215ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 387/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 388/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 389/500
652/652 [==============================] - 139s 212ms/step - loss: 0.5640 - val_loss: 0.5689
Epoch 390/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 391/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 392/500
652/652 [==============================] - 139s 213ms/step - loss: 0.5640 - val_loss: 0.5688
Epoch 393/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5639 - val_loss: 0.5688
Epoch 394/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5639 - val_loss: 0.5688
Epoch 395/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 396/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 397/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5688
Epoch 398/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5639 - val_loss: 0.5688
Epoch 399/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 400/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5688
Epoch 401/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 402/500
652/652 [==============================] - 188s 288ms/step - loss: 0.5639 - val_loss: 0.5688
Epoch 403/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 404/500
652/652 [==============================] - 137s 209ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 405/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 406/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 407/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5690
Epoch 408/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 409/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 410/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 411/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5688
Epoch 412/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 413/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5690
Epoch 414/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 415/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 416/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5639 - val_loss: 0.5690
Epoch 417/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 418/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 419/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5639 - val_loss: 0.5690
Epoch 420/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 421/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5690
Epoch 422/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 423/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5690
Epoch 424/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5690
Epoch 425/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 426/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5639 - val_loss: 0.5689
Epoch 427/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5639 - val_loss: 0.5690
Epoch 428/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5638 - val_loss: 0.5689
Epoch 429/500
652/652 [==============================] - 144s 221ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 430/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 431/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 432/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 433/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 434/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 435/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 436/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 437/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 438/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 439/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 440/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 441/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 442/500
652/652 [==============================] - 139s 213ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 443/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 444/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 445/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 446/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 447/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 448/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5690
Epoch 449/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 450/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 451/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 452/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 453/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 454/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5638 - val_loss: 0.5692
Epoch 455/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 456/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 457/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 458/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5638 - val_loss: 0.5692
Epoch 459/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 460/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 461/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5638 - val_loss: 0.5692
Epoch 462/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 463/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5638 - val_loss: 0.5691
Epoch 464/500
652/652 [==============================] - 133s 204ms/step - loss: 0.5638 - val_loss: 0.5692
Epoch 465/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5638 - val_loss: 0.5692
Epoch 466/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5637 - val_loss: 0.5691
Epoch 467/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 468/500
652/652 [==============================] - 133s 204ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 469/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 470/500
652/652 [==============================] - 137s 210ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 471/500
652/652 [==============================] - 156s 238ms/step - loss: 0.5637 - val_loss: 0.5691
Epoch 472/500
652/652 [==============================] - 147s 224ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 473/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 474/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 475/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5637 - val_loss: 0.5691
Epoch 476/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5691
Epoch 477/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 478/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 479/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 480/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 481/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 482/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 483/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 484/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 485/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 486/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 487/500
652/652 [==============================] - 136s 209ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 488/500
652/652 [==============================] - 138s 211ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 489/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 490/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 491/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 492/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 493/500
652/652 [==============================] - 133s 204ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 494/500
652/652 [==============================] - 134s 206ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 495/500
652/652 [==============================] - 136s 208ms/step - loss: 0.5637 - val_loss: 0.5692
Epoch 496/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 497/500
652/652 [==============================] - 135s 207ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 498/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 499/500
652/652 [==============================] - 134s 205ms/step - loss: 0.5637 - val_loss: 0.5693
Epoch 500/500
652/652 [==============================] - 135s 206ms/step - loss: 0.5637 - val_loss: 0.5693
2022-04-19 05:51:08.566594: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
(sump-venv) (sump-venv) [rda2tc@affogato13 12encoderDreamBigger]$ 