(sump-venv) [rda2tc@affogato15 11encoderCopy2]$ python trainModel.py 
(40000,)
(36000,)
2022-04-04 17:35:14.316716: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-04 17:35:16.627045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1
2022-04-04 17:35:16.628742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10417 MB memory:  -> device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1
2022-04-04 17:35:16.629777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10417 MB memory:  -> device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1
2022-04-04 17:35:16.631288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10417 MB memory:  -> device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 64, 1024, 64)      640       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 32, 512, 64)      0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 32, 512, 32)       18464     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 16, 256, 32)      0         
 2D)                                                             
                                                                 
 conv2d_2 (Conv2D)           (None, 16, 256, 16)       4624      
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 8, 128, 16)       0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 16384)             0         
                                                                 
 dense (Dense)               (None, 4096)              67112960  
                                                                 
 dense_1 (Dense)             (None, 4096)              16781312  
                                                                 
 reshape (Reshape)           (None, 8, 128, 4)         0         
                                                                 
 conv2d_3 (Conv2D)           (None, 8, 128, 16)        592       
                                                                 
 up_sampling2d (UpSampling2D  (None, 16, 256, 16)      0         
 )                                                               
                                                                 
 conv2d_4 (Conv2D)           (None, 16, 256, 32)       4640      
                                                                 
 up_sampling2d_1 (UpSampling  (None, 32, 512, 32)      0         
 2D)                                                             
                                                                 
 conv2d_5 (Conv2D)           (None, 32, 512, 64)       18496     
                                                                 
 up_sampling2d_2 (UpSampling  (None, 64, 1024, 64)     0         
 2D)                                                             
                                                                 
 conv2d_6 (Conv2D)           (None, 64, 1024, 1)       577       
                                                                 
=================================================================
Total params: 83,942,305
Trainable params: 83,942,305
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
2022-04-04 17:35:21.542257: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
2022-04-04 17:35:23.090536: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-04-04 17:35:23.289826: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-04-04 17:35:23.289949: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2022-04-04 17:35:24.461545: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-04-04 17:35:24.509641: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-04-04 17:35:24.722184: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.59GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
360/360 [==============================] - 449s 1s/step - loss: 0.5860 - val_loss: 0.5766
Epoch 2/20
360/360 [==============================] - 153s 422ms/step - loss: 0.5747 - val_loss: 0.5725
Epoch 3/20
360/360 [==============================] - 151s 418ms/step - loss: 0.5725 - val_loss: 0.5711
Epoch 4/20
360/360 [==============================] - 154s 426ms/step - loss: 0.5713 - val_loss: 0.5702
Epoch 5/20
360/360 [==============================] - 152s 420ms/step - loss: 0.5703 - val_loss: 0.5693
Epoch 6/20
360/360 [==============================] - 159s 441ms/step - loss: 0.5696 - val_loss: 0.5687
Epoch 7/20
360/360 [==============================] - 153s 424ms/step - loss: 0.5690 - val_loss: 0.5684
Epoch 8/20
360/360 [==============================] - 152s 422ms/step - loss: 0.5686 - val_loss: 0.5679
Epoch 9/20
360/360 [==============================] - 153s 424ms/step - loss: 0.5682 - val_loss: 0.5678
Epoch 10/20
360/360 [==============================] - 152s 420ms/step - loss: 0.5678 - val_loss: 0.5673
Epoch 11/20
360/360 [==============================] - 148s 410ms/step - loss: 0.5676 - val_loss: 0.5669
Epoch 12/20
360/360 [==============================] - 148s 408ms/step - loss: 0.5673 - val_loss: 0.5669
Epoch 13/20
360/360 [==============================] - 147s 408ms/step - loss: 0.5671 - val_loss: 0.5665
Epoch 14/20
360/360 [==============================] - 154s 426ms/step - loss: 0.5669 - val_loss: 0.5664
Epoch 15/20
360/360 [==============================] - 148s 408ms/step - loss: 0.5667 - val_loss: 0.5663
Epoch 16/20
360/360 [==============================] - 149s 412ms/step - loss: 0.5665 - val_loss: 0.5660
Epoch 17/20
360/360 [==============================] - 150s 415ms/step - loss: 0.5664 - val_loss: 0.5660
Epoch 18/20
360/360 [==============================] - 148s 410ms/step - loss: 0.5662 - val_loss: 0.5659
Epoch 19/20
360/360 [==============================] - 148s 410ms/step - loss: 0.5661 - val_loss: 0.5657
Epoch 20/20
360/360 [==============================] - 148s 410ms/step - loss: 0.5660 - val_loss: 0.5656
2022-04-04 18:35:48.500856: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
[rda2tc@portal03 11encoderCopy2]$ cat trainModel.py 
import numpy as np
import tensorflow as tf


from tensorflow.keras import layers
from tensorflow import keras
from keras.models import Sequential

from PIL import Image
from PIL import ImageOps


from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model

import glob, os
import struct

# ----------------------------------------------------------------------------------------------------

# https://blog.keras.io/building-autoencoders-in-keras.html
# https://ai.stackexchange.com/questions/19891/how-to-add-a-dense-layer-after-a-2d-convolutional-layer-in-a-convolutional-autoe
def create_model():
  model = Sequential()

  # Encoder
  model.add(layers.Input(shape=(64, 1024, 1)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same')) # orig 16
  model.add(layers.MaxPooling2D((2, 2), padding='same'))
  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same')) # orig 8
  model.add(layers.MaxPooling2D((2, 2), padding='same'))
  model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same')) # orig 8
  model.add(layers.MaxPooling2D((2, 2), padding='same'))
  model.add(layers.Flatten())
  model.add(layers.Dense(4096, activation="sigmoid"))
  
  # Decoder 
  model.add(layers.Dense(units=4096,activation='sigmoid'))
  model.add(layers.Reshape((8, 128, 4)))
  model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same')) # orig 8
  model.add(layers.UpSampling2D((2, 2)))
  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same')) # orig 8
  model.add(layers.UpSampling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same')) # orig 16
  model.add(layers.UpSampling2D((2, 2)))
  model.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))

  return model
