(sump-venv) (sump-venv) [rda2tc@affogato15 16enc3]$ python trainModel4.py 
(40000,)
(32000,)
2022-04-15 17:02:38.839796: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-15 17:02:44.931233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1
2022-04-15 17:02:45.009511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10417 MB memory:  -> device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1
2022-04-15 17:02:45.011227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10417 MB memory:  -> device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1
2022-04-15 17:02:45.012295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10417 MB memory:  -> device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 64, 64, 16)        160       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 32, 32, 16)       0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 32, 32, 8)         1160      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 16, 16, 8)        0         
 2D)                                                             
                                                                 
 conv2d_2 (Conv2D)           (None, 16, 16, 8)         584       
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 8, 8, 8)          0         
 2D)                                                             
                                                                 
 conv2d_3 (Conv2D)           (None, 8, 8, 8)           584       
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 4, 4, 8)          0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 128)               0         
                                                                 
 dense (Dense)               (None, 128)               16512     
                                                                 
 dense_1 (Dense)             (None, 64)                8256      
                                                                 
 dense_2 (Dense)             (None, 64)                4160      
                                                                 
 dense_3 (Dense)             (None, 128)               8320      
                                                                 
 reshape (Reshape)           (None, 4, 4, 8)           0         
                                                                 
 conv2d_4 (Conv2D)           (None, 4, 4, 8)           584       
                                                                 
 up_sampling2d (UpSampling2D  (None, 8, 8, 8)          0         
 )                                                               
                                                                 
 conv2d_5 (Conv2D)           (None, 8, 8, 8)           584       
                                                                 
 up_sampling2d_1 (UpSampling  (None, 16, 16, 8)        0         
 2D)                                                             
                                                                 
 conv2d_6 (Conv2D)           (None, 16, 16, 8)         584       
                                                                 
 up_sampling2d_2 (UpSampling  (None, 32, 32, 8)        0         
 2D)                                                             
                                                                 
 conv2d_7 (Conv2D)           (None, 32, 32, 16)        1168      
                                                                 
 up_sampling2d_3 (UpSampling  (None, 64, 64, 16)       0         
 2D)                                                             
                                                                 
 conv2d_8 (Conv2D)           (None, 64, 64, 1)         145       
                                                                 
=================================================================
Total params: 42,801
Trainable params: 42,801
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/200
2022-04-15 17:02:52.527039: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
250/250 [==============================] - 350s 1s/step - loss: 0.4944 - val_loss: 0.4184
Epoch 2/200
250/250 [==============================] - 81s 324ms/step - loss: 0.4035 - val_loss: 0.3913
Epoch 3/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3856 - val_loss: 0.3832
Epoch 4/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3770 - val_loss: 0.3739
Epoch 5/200
250/250 [==============================] - 88s 351ms/step - loss: 0.3724 - val_loss: 0.3720
Epoch 6/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3684 - val_loss: 0.3656
Epoch 7/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3643 - val_loss: 0.3621
Epoch 8/200
250/250 [==============================] - 79s 318ms/step - loss: 0.3605 - val_loss: 0.3585
Epoch 9/200
250/250 [==============================] - 79s 318ms/step - loss: 0.3576 - val_loss: 0.3571
Epoch 10/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3552 - val_loss: 0.3594
Epoch 11/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3534 - val_loss: 0.3521
Epoch 12/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3513 - val_loss: 0.3497
Epoch 13/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3493 - val_loss: 0.3472
Epoch 14/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3476 - val_loss: 0.3457
Epoch 15/200
250/250 [==============================] - 79s 318ms/step - loss: 0.3460 - val_loss: 0.3446
Epoch 16/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3444 - val_loss: 0.3432
Epoch 17/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3433 - val_loss: 0.3420
Epoch 18/200
250/250 [==============================] - 82s 330ms/step - loss: 0.3422 - val_loss: 0.3408
Epoch 19/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3410 - val_loss: 0.3398
Epoch 20/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3399 - val_loss: 0.3457
Epoch 21/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3390 - val_loss: 0.3374
Epoch 22/200
250/250 [==============================] - 106s 422ms/step - loss: 0.3380 - val_loss: 0.3398
Epoch 23/200
250/250 [==============================] - 198s 789ms/step - loss: 0.3373 - val_loss: 0.3397
Epoch 24/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3366 - val_loss: 0.3355
Epoch 25/200
250/250 [==============================] - 79s 315ms/step - loss: 0.3358 - val_loss: 0.3358
Epoch 26/200
250/250 [==============================] - 79s 314ms/step - loss: 0.3349 - val_loss: 0.3344
Epoch 27/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3344 - val_loss: 0.3332
Epoch 28/200
250/250 [==============================] - 79s 316ms/step - loss: 0.3340 - val_loss: 0.3329
Epoch 29/200
250/250 [==============================] - 79s 316ms/step - loss: 0.3332 - val_loss: 0.3338
Epoch 30/200
250/250 [==============================] - 79s 315ms/step - loss: 0.3329 - val_loss: 0.3317
Epoch 31/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3326 - val_loss: 0.3332
Epoch 32/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3319 - val_loss: 0.3320
Epoch 33/200
250/250 [==============================] - 117s 468ms/step - loss: 0.3319 - val_loss: 0.3310
Epoch 34/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3313 - val_loss: 0.3308
Epoch 35/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3308 - val_loss: 0.3334
Epoch 36/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3307 - val_loss: 0.3304
Epoch 37/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3301 - val_loss: 0.3295
Epoch 38/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3296 - val_loss: 0.3311
Epoch 39/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3290 - val_loss: 0.3298
Epoch 40/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3286 - val_loss: 0.3277
Epoch 41/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3282 - val_loss: 0.3271
Epoch 42/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3278 - val_loss: 0.3270
Epoch 43/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3270 - val_loss: 0.3265
Epoch 44/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3268 - val_loss: 0.3260
Epoch 45/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3264 - val_loss: 0.3252
Epoch 46/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3259 - val_loss: 0.3252
Epoch 47/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3258 - val_loss: 0.3256
Epoch 48/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3254 - val_loss: 0.3250
Epoch 49/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3249 - val_loss: 0.3263
Epoch 50/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3247 - val_loss: 0.3241
Epoch 51/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3244 - val_loss: 0.3257
Epoch 52/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3241 - val_loss: 0.3238
Epoch 53/200
250/250 [==============================] - 104s 418ms/step - loss: 0.3238 - val_loss: 0.3232
Epoch 54/200
250/250 [==============================] - 93s 371ms/step - loss: 0.3237 - val_loss: 0.3236
Epoch 55/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3233 - val_loss: 0.3235
Epoch 56/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3230 - val_loss: 0.3237
Epoch 57/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3228 - val_loss: 0.3230
Epoch 58/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3223 - val_loss: 0.3222
Epoch 59/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3222 - val_loss: 0.3232
Epoch 60/200
250/250 [==============================] - 84s 336ms/step - loss: 0.3218 - val_loss: 0.3221
Epoch 61/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3215 - val_loss: 0.3217
Epoch 62/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3212 - val_loss: 0.3207
Epoch 63/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3211 - val_loss: 0.3217
Epoch 64/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3205 - val_loss: 0.3206
Epoch 65/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3203 - val_loss: 0.3200
Epoch 66/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3201 - val_loss: 0.3215
Epoch 67/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3200 - val_loss: 0.3191
Epoch 68/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3195 - val_loss: 0.3192
Epoch 69/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3194 - val_loss: 0.3184
Epoch 70/200
250/250 [==============================] - 82s 329ms/step - loss: 0.3191 - val_loss: 0.3193
Epoch 71/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3190 - val_loss: 0.3209
Epoch 72/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3185 - val_loss: 0.3183
Epoch 73/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3187 - val_loss: 0.3184
Epoch 74/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3184 - val_loss: 0.3184
Epoch 75/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3182 - val_loss: 0.3179
Epoch 76/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3177 - val_loss: 0.3172
Epoch 77/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3176 - val_loss: 0.3169
Epoch 78/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3174 - val_loss: 0.3174
Epoch 79/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3172 - val_loss: 0.3171
Epoch 80/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3171 - val_loss: 0.3191
Epoch 81/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3170 - val_loss: 0.3183
Epoch 82/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3167 - val_loss: 0.3181
Epoch 83/200
250/250 [==============================] - 82s 329ms/step - loss: 0.3165 - val_loss: 0.3165
Epoch 84/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3164 - val_loss: 0.3163
Epoch 85/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3161 - val_loss: 0.3154
Epoch 86/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3161 - val_loss: 0.3183
Epoch 87/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3157 - val_loss: 0.3155
Epoch 88/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3158 - val_loss: 0.3151
Epoch 89/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3156 - val_loss: 0.3170
Epoch 90/200
250/250 [==============================] - 115s 461ms/step - loss: 0.3153 - val_loss: 0.3160
Epoch 91/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3151 - val_loss: 0.3157
Epoch 92/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3150 - val_loss: 0.3146
Epoch 93/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3146 - val_loss: 0.3152
Epoch 94/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3147 - val_loss: 0.3153
Epoch 95/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3143 - val_loss: 0.3142
Epoch 96/200
250/250 [==============================] - 83s 333ms/step - loss: 0.3144 - val_loss: 0.3148
Epoch 97/200
250/250 [==============================] - 97s 389ms/step - loss: 0.3140 - val_loss: 0.3138
Epoch 98/200
250/250 [==============================] - 99s 393ms/step - loss: 0.3139 - val_loss: 0.3155
Epoch 99/200
250/250 [==============================] - 96s 383ms/step - loss: 0.3138 - val_loss: 0.3137
Epoch 100/200
250/250 [==============================] - 97s 387ms/step - loss: 0.3135 - val_loss: 0.3134
Epoch 101/200
250/250 [==============================] - 98s 390ms/step - loss: 0.3136 - val_loss: 0.3128
Epoch 102/200
250/250 [==============================] - 93s 371ms/step - loss: 0.3132 - val_loss: 0.3146
Epoch 103/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3132 - val_loss: 0.3128
Epoch 104/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3130 - val_loss: 0.3133
Epoch 105/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3129 - val_loss: 0.3131
Epoch 106/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3130 - val_loss: 0.3122
Epoch 107/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3127 - val_loss: 0.3122
Epoch 108/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3126 - val_loss: 0.3124
Epoch 109/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3127 - val_loss: 0.3129
Epoch 110/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3122 - val_loss: 0.3137
Epoch 111/200
250/250 [==============================] - 82s 328ms/step - loss: 0.3123 - val_loss: 0.3125
Epoch 112/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3123 - val_loss: 0.3118
Epoch 113/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3120 - val_loss: 0.3115
Epoch 114/200
250/250 [==============================] - 103s 413ms/step - loss: 0.3119 - val_loss: 0.3120
Epoch 115/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3119 - val_loss: 0.3116
Epoch 116/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3118 - val_loss: 0.3113
Epoch 117/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3115 - val_loss: 0.3114
Epoch 118/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3115 - val_loss: 0.3124
Epoch 119/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3114 - val_loss: 0.3129
Epoch 120/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3113 - val_loss: 0.3116
Epoch 121/200
250/250 [==============================] - 79s 318ms/step - loss: 0.3113 - val_loss: 0.3111
Epoch 122/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3111 - val_loss: 0.3118
Epoch 123/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3110 - val_loss: 0.3122
Epoch 124/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3108 - val_loss: 0.3105
Epoch 125/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3108 - val_loss: 0.3107
Epoch 126/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3108 - val_loss: 0.3101
Epoch 127/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3105 - val_loss: 0.3103
Epoch 128/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3105 - val_loss: 0.3099
Epoch 129/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3103 - val_loss: 0.3103
Epoch 130/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3104 - val_loss: 0.3098
Epoch 131/200
250/250 [==============================] - 79s 318ms/step - loss: 0.3100 - val_loss: 0.3110
Epoch 132/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3101 - val_loss: 0.3100
Epoch 133/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3098 - val_loss: 0.3098
Epoch 134/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3098 - val_loss: 0.3103
Epoch 135/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3098 - val_loss: 0.3092
Epoch 136/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3094 - val_loss: 0.3112
Epoch 137/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3096 - val_loss: 0.3100
Epoch 138/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3094 - val_loss: 0.3095
Epoch 139/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3093 - val_loss: 0.3089
Epoch 140/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3093 - val_loss: 0.3094
Epoch 141/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3089 - val_loss: 0.3086
Epoch 142/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3090 - val_loss: 0.3093
Epoch 143/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3089 - val_loss: 0.3089
Epoch 144/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3088 - val_loss: 0.3093
Epoch 145/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3086 - val_loss: 0.3086
Epoch 146/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3086 - val_loss: 0.3088
Epoch 147/200
250/250 [==============================] - 79s 316ms/step - loss: 0.3084 - val_loss: 0.3086
Epoch 148/200
250/250 [==============================] - 99s 398ms/step - loss: 0.3083 - val_loss: 0.3078
Epoch 149/200
250/250 [==============================] - 96s 385ms/step - loss: 0.3081 - val_loss: 0.3080
Epoch 150/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3081 - val_loss: 0.3082
Epoch 151/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3082 - val_loss: 0.3079
Epoch 152/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3078 - val_loss: 0.3075
Epoch 153/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3079 - val_loss: 0.3093
Epoch 154/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3075 - val_loss: 0.3087
Epoch 155/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3076 - val_loss: 0.3080
Epoch 156/200
250/250 [==============================] - 79s 314ms/step - loss: 0.3073 - val_loss: 0.3070
Epoch 157/200
250/250 [==============================] - 79s 315ms/step - loss: 0.3075 - val_loss: 0.3083
Epoch 158/200
250/250 [==============================] - 79s 314ms/step - loss: 0.3072 - val_loss: 0.3068
Epoch 159/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3072 - val_loss: 0.3075
Epoch 160/200
250/250 [==============================] - 79s 316ms/step - loss: 0.3070 - val_loss: 0.3071
Epoch 161/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3071 - val_loss: 0.3069
Epoch 162/200
250/250 [==============================] - 81s 324ms/step - loss: 0.3068 - val_loss: 0.3076
Epoch 163/200
250/250 [==============================] - 338s 1s/step - loss: 0.3068 - val_loss: 0.3087
Epoch 164/200
250/250 [==============================] - 408s 2s/step - loss: 0.3067 - val_loss: 0.3102
Epoch 165/200
250/250 [==============================] - 413s 2s/step - loss: 0.3065 - val_loss: 0.3081
Epoch 166/200
250/250 [==============================] - 418s 2s/step - loss: 0.3065 - val_loss: 0.3063
Epoch 167/200
250/250 [==============================] - 200s 798ms/step - loss: 0.3064 - val_loss: 0.3074
Epoch 168/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3064 - val_loss: 0.3062
Epoch 169/200
250/250 [==============================] - 79s 318ms/step - loss: 0.3062 - val_loss: 0.3068
Epoch 170/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3063 - val_loss: 0.3059
Epoch 171/200
250/250 [==============================] - 85s 341ms/step - loss: 0.3062 - val_loss: 0.3056
Epoch 172/200
250/250 [==============================] - 110s 441ms/step - loss: 0.3060 - val_loss: 0.3056
Epoch 173/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3059 - val_loss: 0.3070
Epoch 174/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3059 - val_loss: 0.3059
Epoch 175/200
250/250 [==============================] - 80s 318ms/step - loss: 0.3057 - val_loss: 0.3063
Epoch 176/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3058 - val_loss: 0.3070
Epoch 177/200
250/250 [==============================] - 79s 316ms/step - loss: 0.3057 - val_loss: 0.3072
Epoch 178/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3056 - val_loss: 0.3056
Epoch 179/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3056 - val_loss: 0.3056
Epoch 180/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3052 - val_loss: 0.3052
Epoch 181/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3053 - val_loss: 0.3060
Epoch 182/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3053 - val_loss: 0.3050
Epoch 183/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3050 - val_loss: 0.3054
Epoch 184/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3051 - val_loss: 0.3051
Epoch 185/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3050 - val_loss: 0.3059
Epoch 186/200
250/250 [==============================] - 79s 317ms/step - loss: 0.3049 - val_loss: 0.3049
Epoch 187/200
250/250 [==============================] - 80s 320ms/step - loss: 0.3049 - val_loss: 0.3055
Epoch 188/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3046 - val_loss: 0.3043
Epoch 189/200
250/250 [==============================] - 79s 318ms/step - loss: 0.3045 - val_loss: 0.3048
Epoch 190/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3046 - val_loss: 0.3043
Epoch 191/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3045 - val_loss: 0.3050
Epoch 192/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3043 - val_loss: 0.3044
Epoch 193/200
250/250 [==============================] - 80s 322ms/step - loss: 0.3041 - val_loss: 0.3040
Epoch 194/200
250/250 [==============================] - 81s 323ms/step - loss: 0.3041 - val_loss: 0.3042
Epoch 195/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3042 - val_loss: 0.3047
Epoch 196/200
250/250 [==============================] - 83s 331ms/step - loss: 0.3041 - val_loss: 0.3035
Epoch 197/200
250/250 [==============================] - 82s 330ms/step - loss: 0.3040 - val_loss: 0.3051
Epoch 198/200
250/250 [==============================] - 80s 319ms/step - loss: 0.3039 - val_loss: 0.3045
Epoch 199/200
250/250 [==============================] - 81s 322ms/step - loss: 0.3037 - val_loss: 0.3040
Epoch 200/200
250/250 [==============================] - 80s 321ms/step - loss: 0.3036 - val_loss: 0.3033
2022-04-15 22:05:23.014244: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
(sump-venv) (sump-venv) [rda2tc@affogato15 16enc3]$ ll
