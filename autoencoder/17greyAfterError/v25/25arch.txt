(sp_venv) [rda2tc@affogato15 v7]$ python trainModel.py 
(40000,)
(28000,)
2022-04-29 21:59:37.765918: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-29 21:59:42.597074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1
2022-04-29 21:59:42.655425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10417 MB memory:  -> device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1
2022-04-29 21:59:42.656921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10417 MB memory:  -> device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1
2022-04-29 21:59:42.658930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10417 MB memory:  -> device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 64, 1024, 32)      320       
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 1024, 32)      9248      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 32, 512, 32)      0         
 )                                                               
                                                                 
 conv2d_2 (Conv2D)           (None, 32, 512, 64)       18496     
                                                                 
 conv2d_3 (Conv2D)           (None, 32, 512, 64)       36928     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 16, 256, 64)      0         
 2D)                                                             
                                                                 
 conv2d_4 (Conv2D)           (None, 16, 256, 128)      73856     
                                                                 
 conv2d_5 (Conv2D)           (None, 16, 256, 128)      147584    
                                                                 
 conv2d_6 (Conv2D)           (None, 16, 256, 128)      147584    
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 8, 128, 128)      0         
 2D)                                                             
                                                                 
 conv2d_7 (Conv2D)           (None, 8, 128, 128)       147584    
                                                                 
 conv2d_8 (Conv2D)           (None, 8, 128, 128)       147584    
                                                                 
 conv2d_9 (Conv2D)           (None, 8, 128, 128)       147584    
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 4, 64, 128)       0         
 2D)                                                             
                                                                 
 conv2d_10 (Conv2D)          (None, 4, 64, 128)        147584    
                                                                 
 conv2d_11 (Conv2D)          (None, 4, 64, 128)        147584    
                                                                 
 conv2d_12 (Conv2D)          (None, 4, 64, 128)        147584    
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 2, 32, 128)       0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 8192)              0         
                                                                 
 dense (Dense)               (None, 8192)              67117056  
                                                                 
 dense_1 (Dense)             (None, 8192)              67117056  
                                                                 
 reshape (Reshape)           (None, 2, 32, 128)        0         
                                                                 
 conv2d_13 (Conv2D)          (None, 2, 32, 128)        147584    
                                                                 
 conv2d_14 (Conv2D)          (None, 2, 32, 128)        147584    
                                                                 
 conv2d_15 (Conv2D)          (None, 2, 32, 128)        147584    
                                                                 
 up_sampling2d (UpSampling2D  (None, 4, 64, 128)       0         
 )                                                               
                                                                 
 conv2d_16 (Conv2D)          (None, 4, 64, 128)        147584    
                                                                 
 conv2d_17 (Conv2D)          (None, 4, 64, 128)        147584    
                                                                 
 conv2d_18 (Conv2D)          (None, 4, 64, 128)        147584    
                                                                 
 up_sampling2d_1 (UpSampling  (None, 8, 128, 128)      0         
 2D)                                                             
                                                                 
 conv2d_19 (Conv2D)          (None, 8, 128, 128)       147584    
                                                                 
 conv2d_20 (Conv2D)          (None, 8, 128, 128)       147584    
                                                                 
 conv2d_21 (Conv2D)          (None, 8, 128, 128)       147584    
                                                                 
 up_sampling2d_2 (UpSampling  (None, 16, 256, 128)     0         
 2D)                                                             
                                                                 
 conv2d_22 (Conv2D)          (None, 16, 256, 64)       73792     
                                                                 
 conv2d_23 (Conv2D)          (None, 16, 256, 64)       36928     
                                                                 
 up_sampling2d_3 (UpSampling  (None, 32, 512, 64)      0         
 2D)                                                             
                                                                 
 conv2d_24 (Conv2D)          (None, 32, 512, 32)       18464     
                                                                 
 conv2d_25 (Conv2D)          (None, 32, 512, 32)       9248      
                                                                 
 up_sampling2d_4 (UpSampling  (None, 64, 1024, 32)     0         
 2D)                                                             
                                                                 
 conv2d_26 (Conv2D)          (None, 64, 1024, 1)       289       
                                                                 
=================================================================
Total params: 137,020,609
Trainable params: 137,020,609
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
2022-04-29 21:59:47.044772: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
875/875 [==============================] - 670s 761ms/step - loss: 0.5908 - val_loss: 0.5815
Epoch 2/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5816 - val_loss: 0.5814
Epoch 3/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5814 - val_loss: 0.5812
Epoch 4/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5813 - val_loss: 0.5813
Epoch 5/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5812 - val_loss: 0.5812
Epoch 6/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5812 - val_loss: 0.5812
Epoch 7/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5812 - val_loss: 0.5812
Epoch 8/100
875/875 [==============================] - 212s 242ms/step - loss: 0.5812 - val_loss: 0.5811
Epoch 9/100
875/875 [==============================] - 214s 245ms/step - loss: 0.5812 - val_loss: 0.5811
Epoch 10/100
875/875 [==============================] - 207s 237ms/step - loss: 0.5811 - val_loss: 0.5813
Epoch 11/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5812 - val_loss: 0.5812
Epoch 12/100
875/875 [==============================] - 210s 239ms/step - loss: 0.5811 - val_loss: 0.5811
Epoch 13/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5811
Epoch 14/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5811
Epoch 15/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 16/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 17/100
875/875 [==============================] - 210s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 18/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 19/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5811
Epoch 20/100
875/875 [==============================] - 215s 246ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 21/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 22/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5811
Epoch 23/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 24/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 25/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 26/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5811 - val_loss: 0.5811
Epoch 27/100
875/875 [==============================] - 210s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 28/100
875/875 [==============================] - 213s 243ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 29/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 30/100
875/875 [==============================] - 217s 248ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 31/100
875/875 [==============================] - 239s 273ms/step - loss: 0.5811 - val_loss: 0.5811
Epoch 32/100
875/875 [==============================] - 213s 244ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 33/100
875/875 [==============================] - 222s 254ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 34/100
875/875 [==============================] - 213s 244ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 35/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 36/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 37/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 38/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 39/100
875/875 [==============================] - 224s 256ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 40/100
875/875 [==============================] - 211s 241ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 41/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 42/100
875/875 [==============================] - 207s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 43/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 44/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 45/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 46/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 47/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 48/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 49/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 50/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 51/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 52/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 53/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 54/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 55/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 56/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 57/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 58/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 59/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 60/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 61/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 62/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 63/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 64/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 65/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 66/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 67/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 68/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 69/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 70/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 71/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 72/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 73/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 74/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 75/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 76/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 77/100
875/875 [==============================] - 210s 239ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 78/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 79/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 80/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 81/100
875/875 [==============================] - 207s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 82/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 83/100
875/875 [==============================] - 209s 238ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 84/100
875/875 [==============================] - 208s 237ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 85/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 86/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 87/100
875/875 [==============================] - 211s 241ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 88/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 89/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 90/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 91/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 92/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 93/100
875/875 [==============================] - 214s 244ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 94/100
875/875 [==============================] - 212s 242ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 95/100
875/875 [==============================] - 215s 245ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 96/100
875/875 [==============================] - 213s 244ms/step - loss: 0.5811 - val_loss: 0.5810
Epoch 97/100
875/875 [==============================] - 214s 245ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 98/100
875/875 [==============================] - 209s 239ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 99/100
875/875 [==============================] - 210s 240ms/step - loss: 0.5810 - val_loss: 0.5810
Epoch 100/100
875/875 [==============================] - 208s 238ms/step - loss: 0.5810 - val_loss: 0.5810
2022-04-30 03:57:23.272931: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
(sp_venv) [rda2tc@affogato15 v7]$ client_loop: send disconnect: Broken pipe
garrett@garrett-ubuntu:~$ 
