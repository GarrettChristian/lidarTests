sp_venv) (sp_venv) [rda2tc@affogato11 v4]$ python trainModel.py 
(40000,)
(28000,)
2022-04-29 17:36:55.426642: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-29 17:36:57.623360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1
2022-04-29 17:36:57.624506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10417 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1
2022-04-29 17:36:57.625047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10417 MB memory:  -> device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1
2022-04-29 17:36:57.625567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10417 MB memory:  -> device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 64, 1024, 64)      1664      
                                                                 
 batch_normalization (BatchN  (None, 64, 1024, 64)     256       
 ormalization)                                                   
                                                                 
 max_pooling2d (MaxPooling2D  (None, 32, 512, 64)      0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 32, 512, 32)       18464     
                                                                 
 batch_normalization_1 (Batc  (None, 32, 512, 32)      128       
 hNormalization)                                                 
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 16, 256, 32)      0         
 2D)                                                             
                                                                 
 conv2d_2 (Conv2D)           (None, 16, 256, 16)       4624      
                                                                 
 batch_normalization_2 (Batc  (None, 16, 256, 16)      64        
 hNormalization)                                                 
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 8, 128, 16)       0         
 2D)                                                             
                                                                 
 conv2d_3 (Conv2D)           (None, 8, 128, 8)         1160      
                                                                 
 batch_normalization_3 (Batc  (None, 8, 128, 8)        32        
 hNormalization)                                                 
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 4, 64, 8)         0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 2048)              0         
                                                                 
 dense (Dense)               (None, 2048)              4196352   
                                                                 
 dense_1 (Dense)             (None, 2048)              4196352   
                                                                 
 reshape (Reshape)           (None, 4, 64, 8)          0         
                                                                 
 conv2d_4 (Conv2D)           (None, 4, 64, 8)          584       
                                                                 
 batch_normalization_4 (Batc  (None, 4, 64, 8)         32        
 hNormalization)                                                 
                                                                 
 up_sampling2d (UpSampling2D  (None, 8, 128, 8)        0         
 )                                                               
                                                                 
 conv2d_5 (Conv2D)           (None, 8, 128, 16)        1168      
                                                                 
 batch_normalization_5 (Batc  (None, 8, 128, 16)       64        
 hNormalization)                                                 
                                                                 
 up_sampling2d_1 (UpSampling  (None, 16, 256, 16)      0         
 2D)                                                             
                                                                 
 conv2d_6 (Conv2D)           (None, 16, 256, 32)       4640      
                                                                 
 batch_normalization_6 (Batc  (None, 16, 256, 32)      128       
 hNormalization)                                                 
                                                                 
 up_sampling2d_2 (UpSampling  (None, 32, 512, 32)      0         
 2D)                                                             
                                                                 
 conv2d_7 (Conv2D)           (None, 32, 512, 64)       51264     
                                                                 
 batch_normalization_7 (Batc  (None, 32, 512, 64)      256       
 hNormalization)                                                 
                                                                 
 up_sampling2d_3 (UpSampling  (None, 64, 1024, 64)     0         
 2D)                                                             
                                                                 
 conv2d_8 (Conv2D)           (None, 64, 1024, 1)       577       
                                                                 
=================================================================
Total params: 8,477,809
Trainable params: 8,477,329
Non-trainable params: 480
_________________________________________________________________
None
Epoch 1/200
2022-04-29 17:37:02.425989: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
437/437 [==============================] - 634s 1s/step - loss: 0.5911 - val_loss: 0.5806
Epoch 2/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5755 - val_loss: 0.5750
Epoch 3/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5736 - val_loss: 0.5731
Epoch 4/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5729 - val_loss: 0.5726
Epoch 5/200
437/437 [==============================] - 145s 333ms/step - loss: 0.5724 - val_loss: 0.5722
Epoch 6/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5719 - val_loss: 0.5718
Epoch 7/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5715 - val_loss: 0.5714
Epoch 8/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5711 - val_loss: 0.5711
Epoch 9/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5708 - val_loss: 0.5706
Epoch 10/200
437/437 [==============================] - 149s 340ms/step - loss: 0.5704 - val_loss: 0.5704
Epoch 11/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5700 - val_loss: 0.5700
Epoch 12/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5697 - val_loss: 0.5696
Epoch 13/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5694 - val_loss: 0.5695
Epoch 14/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5691 - val_loss: 0.5691
Epoch 15/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5689 - val_loss: 0.5690
Epoch 16/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5687 - val_loss: 0.5687
Epoch 17/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5685 - val_loss: 0.5685
Epoch 18/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5683 - val_loss: 0.5684
Epoch 19/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5682 - val_loss: 0.5684
Epoch 20/200
437/437 [==============================] - 156s 357ms/step - loss: 0.5680 - val_loss: 0.5681
Epoch 21/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5679 - val_loss: 0.5680
Epoch 22/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5678 - val_loss: 0.5678
Epoch 23/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5677 - val_loss: 0.5678
Epoch 24/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5676 - val_loss: 0.5677
Epoch 25/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5675 - val_loss: 0.5676
Epoch 26/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5674 - val_loss: 0.5675
Epoch 27/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5673 - val_loss: 0.5674
Epoch 28/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5672 - val_loss: 0.5674
Epoch 29/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5672 - val_loss: 0.5674
Epoch 30/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5671 - val_loss: 0.5674
Epoch 31/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5671 - val_loss: 0.5673
Epoch 32/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5670 - val_loss: 0.5672
Epoch 33/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5670 - val_loss: 0.5676
Epoch 34/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5669 - val_loss: 0.5671
Epoch 35/200
437/437 [==============================] - 145s 333ms/step - loss: 0.5668 - val_loss: 0.5671
Epoch 36/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5668 - val_loss: 0.5671
Epoch 37/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5668 - val_loss: 0.5672
Epoch 38/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5667 - val_loss: 0.5671
Epoch 39/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5667 - val_loss: 0.5671
Epoch 40/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5667 - val_loss: 0.5670
Epoch 41/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5666 - val_loss: 0.5671
Epoch 42/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5666 - val_loss: 0.5671
Epoch 43/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5666 - val_loss: 0.5669
Epoch 44/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5665 - val_loss: 0.5671
Epoch 45/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5665 - val_loss: 0.5668
Epoch 46/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5665 - val_loss: 0.5668
Epoch 47/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5665 - val_loss: 0.5668
Epoch 48/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5664 - val_loss: 0.5668
Epoch 49/200
437/437 [==============================] - 145s 333ms/step - loss: 0.5664 - val_loss: 0.5667
Epoch 50/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5664 - val_loss: 0.5669
Epoch 51/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5664 - val_loss: 0.5667
Epoch 52/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5663 - val_loss: 0.5668
Epoch 53/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5663 - val_loss: 0.5667
Epoch 54/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5663 - val_loss: 0.5667
Epoch 55/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5663 - val_loss: 0.5667
Epoch 56/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5663 - val_loss: 0.5667
Epoch 57/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5663 - val_loss: 0.5666
Epoch 58/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5662 - val_loss: 0.5666
Epoch 59/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5662 - val_loss: 0.5666
Epoch 60/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5662 - val_loss: 0.5666
Epoch 61/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5662 - val_loss: 0.5666
Epoch 62/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5662 - val_loss: 0.5666
Epoch 63/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5662 - val_loss: 0.5665
Epoch 64/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5661 - val_loss: 0.5666
Epoch 65/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5661 - val_loss: 0.5665
Epoch 66/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5661 - val_loss: 0.5666
Epoch 67/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5661 - val_loss: 0.5665
Epoch 68/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5661 - val_loss: 0.5666
Epoch 69/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5661 - val_loss: 0.5665
Epoch 70/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5660 - val_loss: 0.5668
Epoch 71/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5660 - val_loss: 0.5665
Epoch 72/200
437/437 [==============================] - 145s 331ms/step - loss: 0.5661 - val_loss: 0.5665
Epoch 73/200
437/437 [==============================] - 149s 341ms/step - loss: 0.5660 - val_loss: 0.5665
Epoch 74/200
437/437 [==============================] - 150s 344ms/step - loss: 0.5660 - val_loss: 0.5664
Epoch 75/200
437/437 [==============================] - 150s 343ms/step - loss: 0.5660 - val_loss: 0.5664
Epoch 76/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5660 - val_loss: 0.5666
Epoch 77/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5660 - val_loss: 0.5665
Epoch 78/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5659 - val_loss: 0.5664
Epoch 79/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5659 - val_loss: 0.5664
Epoch 80/200
437/437 [==============================] - 152s 348ms/step - loss: 0.5659 - val_loss: 0.5665
Epoch 81/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5659 - val_loss: 0.5664
Epoch 82/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5659 - val_loss: 0.5664
Epoch 83/200
437/437 [==============================] - 150s 342ms/step - loss: 0.5659 - val_loss: 0.5665
Epoch 84/200
437/437 [==============================] - 145s 331ms/step - loss: 0.5659 - val_loss: 0.5664
Epoch 85/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5659 - val_loss: 0.5665
Epoch 86/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5659 - val_loss: 0.5664
Epoch 87/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5659 - val_loss: 0.5663
Epoch 88/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5659 - val_loss: 0.5665
Epoch 89/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5659 - val_loss: 0.5664
Epoch 90/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 91/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 92/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 93/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 94/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 95/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 96/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 97/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 98/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5658 - val_loss: 0.5665
Epoch 99/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5658 - val_loss: 0.5663
Epoch 100/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5657 - val_loss: 0.5663
Epoch 101/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5657 - val_loss: 0.5663
Epoch 102/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5657 - val_loss: 0.5662
Epoch 103/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5657 - val_loss: 0.5662
Epoch 104/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5657 - val_loss: 0.5664
Epoch 105/200
437/437 [==============================] - 149s 340ms/step - loss: 0.5657 - val_loss: 0.5662
Epoch 106/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5657 - val_loss: 0.5663
Epoch 107/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5657 - val_loss: 0.5663
Epoch 108/200
437/437 [==============================] - 147s 337ms/step - loss: 0.5657 - val_loss: 0.5662
Epoch 109/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5657 - val_loss: 0.5663
Epoch 110/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5657 - val_loss: 0.5662
Epoch 111/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5657 - val_loss: 0.5662
Epoch 112/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5657 - val_loss: 0.5663
Epoch 113/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5657 - val_loss: 0.5662
Epoch 114/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5656 - val_loss: 0.5664
Epoch 115/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 116/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 117/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5656 - val_loss: 0.5663
Epoch 118/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5656 - val_loss: 0.5661
Epoch 119/200
437/437 [==============================] - 152s 347ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 120/200
437/437 [==============================] - 159s 364ms/step - loss: 0.5656 - val_loss: 0.5663
Epoch 121/200
437/437 [==============================] - 145s 331ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 122/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 123/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 124/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 125/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 126/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 127/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5656 - val_loss: 0.5663
Epoch 128/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5656 - val_loss: 0.5663
Epoch 129/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5656 - val_loss: 0.5661
Epoch 130/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 131/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5656 - val_loss: 0.5662
Epoch 132/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 133/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5656 - val_loss: 0.5663
Epoch 134/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 135/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 136/200
437/437 [==============================] - 155s 354ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 137/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5655 - val_loss: 0.5662
Epoch 138/200
437/437 [==============================] - 144s 330ms/step - loss: 0.5655 - val_loss: 0.5662
Epoch 139/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5655 - val_loss: 0.5663
Epoch 140/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 141/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 142/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5655 - val_loss: 0.5662
Epoch 143/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5655 - val_loss: 0.5664
Epoch 144/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 145/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 146/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 147/200
437/437 [==============================] - 148s 340ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 148/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 149/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 150/200
437/437 [==============================] - 154s 353ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 151/200
437/437 [==============================] - 175s 401ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 152/200
437/437 [==============================] - 173s 394ms/step - loss: 0.5655 - val_loss: 0.5662
Epoch 153/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 154/200
437/437 [==============================] - 167s 381ms/step - loss: 0.5655 - val_loss: 0.5661
Epoch 155/200
437/437 [==============================] - 159s 365ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 156/200
437/437 [==============================] - 149s 340ms/step - loss: 0.5654 - val_loss: 0.5662
Epoch 157/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 158/200
437/437 [==============================] - 145s 333ms/step - loss: 0.5654 - val_loss: 0.5662
Epoch 159/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 160/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 161/200
437/437 [==============================] - 147s 337ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 162/200
437/437 [==============================] - 163s 374ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 163/200
437/437 [==============================] - 165s 377ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 164/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 165/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 166/200
437/437 [==============================] - 147s 336ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 167/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 168/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 169/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 170/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 171/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 172/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 173/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 174/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 175/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 176/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5662
Epoch 177/200
437/437 [==============================] - 145s 333ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 178/200
437/437 [==============================] - 145s 333ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 179/200
437/437 [==============================] - 145s 331ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 180/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 181/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 182/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5653 - val_loss: 0.5662
Epoch 183/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5661
Epoch 184/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5654 - val_loss: 0.5660
Epoch 185/200
437/437 [==============================] - 157s 359ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 186/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 187/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5653 - val_loss: 0.5662
Epoch 188/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 189/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5653 - val_loss: 0.5662
Epoch 190/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 191/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 192/200
437/437 [==============================] - 145s 332ms/step - loss: 0.5653 - val_loss: 0.5661
Epoch 193/200
437/437 [==============================] - 146s 333ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 194/200
437/437 [==============================] - 145s 333ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 195/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 196/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 197/200
437/437 [==============================] - 145s 333ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 198/200
437/437 [==============================] - 147s 335ms/step - loss: 0.5653 - val_loss: 0.5661
Epoch 199/200
437/437 [==============================] - 146s 335ms/step - loss: 0.5653 - val_loss: 0.5660
Epoch 200/200
437/437 [==============================] - 146s 334ms/step - loss: 0.5653 - val_loss: 0.5659
2022-04-30 01:55:33.221285: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
(sp_venv) (sp_venv) [rda2tc@affogato11 v4]$ client_loop: send disconnect: Broken pipe
garrett@garrett-ubuntu:~$ 

