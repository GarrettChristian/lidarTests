(sump-venv) [rda2tc@ai02 15vaeAttempt]$ python trainModel.py 
(23201,)
2022-04-20 20:04:50.166225: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 20:04:55.967840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1
2022-04-20 20:04:56.044133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10417 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1
2022-04-20 20:04:56.046216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10417 MB memory:  -> device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1
2022-04-20 20:04:56.047728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10417 MB memory:  -> device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1
Model: "encoder"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 64, 1024, 1  0           []                               
                                )]                                                                
                                                                                                  
 conv2d (Conv2D)                (None, 32, 512, 32)  320         ['input_1[0][0]']                
                                                                                                  
 conv2d_1 (Conv2D)              (None, 16, 256, 64)  18496       ['conv2d[0][0]']                 
                                                                                                  
 conv2d_2 (Conv2D)              (None, 16, 256, 64)  36928       ['conv2d_1[0][0]']               
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 8, 128, 64)   0           ['conv2d_2[0][0]']               
                                                                                                  
 conv2d_3 (Conv2D)              (None, 8, 128, 64)   36928       ['max_pooling2d[0][0]']          
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, 4, 64, 64)   0           ['conv2d_3[0][0]']               
                                                                                                  
 conv2d_4 (Conv2D)              (None, 4, 64, 64)    36928       ['max_pooling2d_1[0][0]']        
                                                                                                  
 max_pooling2d_2 (MaxPooling2D)  (None, 2, 32, 64)   0           ['conv2d_4[0][0]']               
                                                                                                  
 flatten (Flatten)              (None, 4096)         0           ['max_pooling2d_2[0][0]']        
                                                                                                  
 dense (Dense)                  (None, 4096)         16781312    ['flatten[0][0]']                
                                                                                                  
 z_mean (Dense)                 (None, 2)            8194        ['dense[0][0]']                  
                                                                                                  
 z_log_var (Dense)              (None, 2)            8194        ['dense[0][0]']                  
                                                                                                  
 sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 
                                                                  'z_log_var[0][0]']              
                                                                                                  
==================================================================================================
Total params: 16,927,300
Trainable params: 16,927,300
Non-trainable params: 0
__________________________________________________________________________________________________
None
Model: "decoder"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 2)]               0         
                                                                 
 dense_1 (Dense)             (None, 4096)              12288     
                                                                 
 reshape (Reshape)           (None, 2, 32, 64)         0         
                                                                 
 conv2d_transpose (Conv2DTra  (None, 2, 32, 64)        36928     
 nspose)                                                         
                                                                 
 up_sampling2d (UpSampling2D  (None, 4, 64, 64)        0         
 )                                                               
                                                                 
 conv2d_transpose_1 (Conv2DT  (None, 4, 64, 64)        36928     
 ranspose)                                                       
                                                                 
 up_sampling2d_1 (UpSampling  (None, 8, 128, 64)       0         
 2D)                                                             
                                                                 
 conv2d_transpose_2 (Conv2DT  (None, 8, 128, 64)       36928     
 ranspose)                                                       
                                                                 
 up_sampling2d_2 (UpSampling  (None, 16, 256, 64)      0         
 2D)                                                             
                                                                 
 conv2d_transpose_3 (Conv2DT  (None, 32, 512, 64)      36928     
 ranspose)                                                       
                                                                 
 conv2d_transpose_4 (Conv2DT  (None, 64, 1024, 32)     18464     
 ranspose)                                                       
                                                                 
 conv2d_transpose_5 (Conv2DT  (None, 64, 1024, 1)      289       
 ranspose)                                                       
                                                                 
=================================================================
Total params: 178,753
Trainable params: 178,753
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/50
2022-04-20 20:05:12.829349: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101
90/90 [==============================] - 84s 761ms/step - loss: 6196152.0731 - reconstruction_loss: 77312.6797 - kl_loss: 1874422.3750
Epoch 2/50
90/90 [==============================] - 68s 697ms/step - loss: 41449.7686 - reconstruction_loss: 40468.7852 - kl_loss: 10.1830
Epoch 3/50
90/90 [==============================] - 73s 743ms/step - loss: 38542.4794 - reconstruction_loss: 38437.4141 - kl_loss: 18.6932
Epoch 4/50
90/90 [==============================] - 69s 710ms/step - loss: 38320.4118 - reconstruction_loss: 38284.0117 - kl_loss: 16.2131
Epoch 5/50
90/90 [==============================] - 72s 721ms/step - loss: 38240.9502 - reconstruction_loss: 38203.0625 - kl_loss: 15.2278
Epoch 6/50
90/90 [==============================] - 73s 752ms/step - loss: 38189.8472 - reconstruction_loss: 38156.0039 - kl_loss: 13.8991
Epoch 7/50
90/90 [==============================] - 68s 730ms/step - loss: 38149.5357 - reconstruction_loss: 38129.3633 - kl_loss: 13.0402
Epoch 8/50
90/90 [==============================] - 69s 720ms/step - loss: 38124.5143 - reconstruction_loss: 38112.9648 - kl_loss: 12.0997
Epoch 9/50
90/90 [==============================] - 69s 732ms/step - loss: 38115.3030 - reconstruction_loss: 38099.4648 - kl_loss: 11.4973
Epoch 10/50
90/90 [==============================] - 73s 721ms/step - loss: 38116.3823 - reconstruction_loss: 38092.2227 - kl_loss: 10.9404
Epoch 11/50
90/90 [==============================] - 68s 702ms/step - loss: 38070.0686 - reconstruction_loss: 38064.7617 - kl_loss: 11.1604
Epoch 12/50
90/90 [==============================] - 73s 737ms/step - loss: 38082.5777 - reconstruction_loss: 38064.5352 - kl_loss: 10.8167
Epoch 13/50
90/90 [==============================] - 68s 712ms/step - loss: 38074.6713 - reconstruction_loss: 38051.3711 - kl_loss: 10.2376
Epoch 14/50
90/90 [==============================] - 68s 727ms/step - loss: 38042.8480 - reconstruction_loss: 38043.3398 - kl_loss: 10.2444
Epoch 15/50
90/90 [==============================] - 68s 718ms/step - loss: 38051.6672 - reconstruction_loss: 38035.4258 - kl_loss: 9.9911
Epoch 16/50
90/90 [==============================] - 68s 709ms/step - loss: 38043.6605 - reconstruction_loss: 38030.6328 - kl_loss: 9.7271
Epoch 17/50
90/90 [==============================] - 68s 717ms/step - loss: 38030.7852 - reconstruction_loss: 38022.4727 - kl_loss: 9.5681
Epoch 18/50
90/90 [==============================] - 69s 726ms/step - loss: 38027.6125 - reconstruction_loss: 38020.5352 - kl_loss: 9.3503
Epoch 19/50
90/90 [==============================] - 69s 710ms/step - loss: 38024.4381 - reconstruction_loss: 38018.7852 - kl_loss: 9.1320
Epoch 20/50
90/90 [==============================] - 68s 729ms/step - loss: 38019.6374 - reconstruction_loss: 38009.3438 - kl_loss: 9.0473
Epoch 21/50
90/90 [==============================] - 68s 720ms/step - loss: 38022.4373 - reconstruction_loss: 38016.4883 - kl_loss: 8.7688
Epoch 22/50
90/90 [==============================] - 68s 719ms/step - loss: 38012.3374 - reconstruction_loss: 38000.5195 - kl_loss: 8.7939
Epoch 23/50
90/90 [==============================] - 68s 725ms/step - loss: 38024.1020 - reconstruction_loss: 37998.1211 - kl_loss: 8.6974
Epoch 24/50
90/90 [==============================] - 68s 720ms/step - loss: 38016.1945 - reconstruction_loss: 38004.5156 - kl_loss: 8.4739
Epoch 25/50
90/90 [==============================] - 69s 708ms/step - loss: 37994.5751 - reconstruction_loss: 37992.3281 - kl_loss: 8.5025
Epoch 26/50
90/90 [==============================] - 68s 728ms/step - loss: 38002.9797 - reconstruction_loss: 37992.4766 - kl_loss: 8.3888
Epoch 27/50
90/90 [==============================] - 68s 730ms/step - loss: 37991.7712 - reconstruction_loss: 37988.1367 - kl_loss: 8.3200
Epoch 28/50
90/90 [==============================] - 68s 724ms/step - loss: 37996.0183 - reconstruction_loss: 37988.0078 - kl_loss: 8.2184
Epoch 29/50
90/90 [==============================] - 68s 717ms/step - loss: 37996.8725 - reconstruction_loss: 37987.8086 - kl_loss: 8.1861
Epoch 30/50
90/90 [==============================] - 68s 712ms/step - loss: 37990.3473 - reconstruction_loss: 37982.6992 - kl_loss: 8.0925
Epoch 31/50
90/90 [==============================] - 68s 712ms/step - loss: 37989.2620 - reconstruction_loss: 37979.8828 - kl_loss: 8.0485
Epoch 32/50
90/90 [==============================] - 68s 714ms/step - loss: 37985.4645 - reconstruction_loss: 37977.7852 - kl_loss: 7.9882
Epoch 33/50
90/90 [==============================] - 68s 720ms/step - loss: 37987.0977 - reconstruction_loss: 37977.7227 - kl_loss: 7.9127
Epoch 34/50
90/90 [==============================] - 68s 717ms/step - loss: 37979.4604 - reconstruction_loss: 37972.4883 - kl_loss: 7.8584
Epoch 35/50
90/90 [==============================] - 69s 710ms/step - loss: 37974.3764 - reconstruction_loss: 37972.2539 - kl_loss: 7.8143
Epoch 36/50
90/90 [==============================] - 73s 745ms/step - loss: 37978.5555 - reconstruction_loss: 37969.4922 - kl_loss: 7.7542
Epoch 37/50
90/90 [==============================] - 68s 727ms/step - loss: 37971.6731 - reconstruction_loss: 37964.3750 - kl_loss: 7.7605
Epoch 38/50
90/90 [==============================] - 69s 705ms/step - loss: 37970.0395 - reconstruction_loss: 37964.4375 - kl_loss: 7.7194
Epoch 39/50
90/90 [==============================] - 68s 704ms/step - loss: 37969.9317 - reconstruction_loss: 37963.1797 - kl_loss: 7.6959
Epoch 40/50
90/90 [==============================] - 68s 719ms/step - loss: 37953.3326 - reconstruction_loss: 37959.3008 - kl_loss: 7.6766
Epoch 41/50
90/90 [==============================] - 68s 724ms/step - loss: 37966.8712 - reconstruction_loss: 37956.9805 - kl_loss: 7.6935
Epoch 42/50
90/90 [==============================] - 68s 712ms/step - loss: 37964.8783 - reconstruction_loss: 37956.5664 - kl_loss: 7.6547
Epoch 43/50
90/90 [==============================] - 68s 730ms/step - loss: 37965.3112 - reconstruction_loss: 37954.5273 - kl_loss: 7.6402
Epoch 44/50
90/90 [==============================] - 68s 715ms/step - loss: 37956.4806 - reconstruction_loss: 37950.8867 - kl_loss: 7.5846
Epoch 45/50
90/90 [==============================] - 68s 714ms/step - loss: 37958.5841 - reconstruction_loss: 37949.7188 - kl_loss: 7.6142
Epoch 46/50
90/90 [==============================] - 68s 718ms/step - loss: 37953.9599 - reconstruction_loss: 37949.1250 - kl_loss: 7.6205
Epoch 47/50
90/90 [==============================] - 68s 719ms/step - loss: 37954.8359 - reconstruction_loss: 37945.3125 - kl_loss: 7.5887
Epoch 48/50
90/90 [==============================] - 68s 721ms/step - loss: 37950.0711 - reconstruction_loss: 37945.8789 - kl_loss: 7.5544
Epoch 49/50
90/90 [==============================] - 68s 721ms/step - loss: 37957.8635 - reconstruction_loss: 37943.6875 - kl_loss: 7.5626
Epoch 50/50
90/90 [==============================] - 68s 725ms/step - loss: 37955.1138 - reconstruction_loss: 37946.4844 - kl_loss: 7.5268